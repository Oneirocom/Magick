// seraph_iterator.test.ts
import { SeraphIterator } from '../seraph_iterator'
import { Seraph } from '../seraphCore'
import { LLMManager } from '../llm_manager'
import { CognitiveFunctionSchema } from '../zod_schemas'

jest.mock('../llm_manager')

describe('SeraphIterator', () => {
  let seraph: Seraph
  let llmManager: LLMManager
  let mockFunctionOutput: string

  beforeEach(() => {
    seraph = new Seraph('Test prompt')
    llmManager = new LLMManager('mock_api_key')
    ;(llmManager.generateResponse as jest.Mock).mockResolvedValue(
      'Mock LLM response'
    )

    // Register a mock cognitive function
    const functionSchema: CognitiveFunctionSchema = {
      name: 'mockFunction',
      description: 'A mock function',
      parameters: {
        param1: { type: 'string', description: 'Parameter 1' },
        param2: { type: 'number', description: 'Parameter 2' },
      },
      examples: [],
    }
    seraph.registerCognitiveFunction(functionSchema)
    mockFunctionOutput = 'Mock function output'
    seraph['cognitiveFunctionExecutor'].executeFunction = jest
      .fn()
      .mockResolvedValue(mockFunctionOutput)
  })

  test('should process function calls generated by the LLM', async () => {
    const conversationId = 'test_conversation'
    const initialResponse = `Mock LLM response <function_calls>
      <invoke>
        <tool_name>mockFunction</tool_name>
        <parameters>
          <param1>value1</param1>
          <param2>42</param2>
        </parameters>
      </invoke>
    </function_calls>`

    const seraphIterator = new SeraphIterator(
      seraph,
      conversationId,
      initialResponse
    )
    const responseIterator = seraphIterator[Symbol.asyncIterator]()

    await responseIterator.next()
    expect(
      seraph['cognitiveFunctionExecutor'].executeFunction
    ).toHaveBeenCalledWith('mockFunction', {
      param1: 'value1',
      param2: 42,
    })
  })

  // Add more test cases for other scenarios
})
